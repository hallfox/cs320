\documentclass[12pt]{article}
 
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{enumerate}
\usepackage{listings}
\usepackage{color}
\usepackage{courier}
 
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
 
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep{\bfseries #1}\hskip \labelsep{\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep{\bfseries #1}\hskip \labelsep{\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep{\bfseries #1}\hskip \labelsep{\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep{\bfseries #1}\hskip \labelsep{\bfseries #2.}]}{\end{trivlist}}
\newenvironment{question}[2][Question]{\begin{trivlist}
\item[\hskip \labelsep{\bfseries #1}\hskip \labelsep{\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep{\bfseries #1}\hskip \labelsep{\bfseries #2.}]}{\end{trivlist}}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize\ttfamily\color{black},
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
 
\lstset{style=mystyle}
\renewcommand{\lstlistingname}{Code}

\begin{document}
 
\title{Comparing Cache Models}
\author{Taylor Foxhall\\
CS 320}
 
\maketitle
\section{Purpose}

In this assignment we look to evaluate the effectiveness of different methods of
caching. We'll use direct caches, set-associative caches, fully-associative
caches, and multiple write-through policies and next-line prefetching.
 
\section{Direct Caching}

Direct caching is consistently the worst estimator, although it seems to pull
ahead for the largest of cache sizes (16 KB). This is what I expected, except in
the last case.

\section{Set-Associative Caching}

This was the most general model, with all other models of the cache being some
derivation or special case of the Set-Associative cache's functionality. For
small caches, this model usually performed much better than the Direct Cache
equivalent, though it was still not the best.

\section{Fully-Associative Caching}

While its simulated implementation was much less efficient than the set
associative caching, fully associative caches performed better than the largetst
way Set-Associative cache. However, the number of ways had a huge increase from
the largest used in the Set-Associate model, and resulted in just a tiny
return in hit counts. Taken into account for the loss in efficiency associated
with scanning the entire cache for a block, this model isn't necessarily the
best option.

\subsection{Hot-Cold Replacement}

Since in reality it is hard to simulate the LRU policy on the hardware
efficiently, Hot-Cold approximation can be used, and as it can be seen, the
replacement policy is less accurate than true LRU replacement, but not enough
that it wouldn't be worth the gain in efficiency.

\section{Write-through Policy}

This model was plainly worse than the general Set-Associative model, except in
one case. This isn't surprising, since we don't update the cache on a miss and
we generally write to memory in a local area, if we miss once, we'll probably
miss again soon. Although, we don't really lose a lot of our accuracy, write
misses must not be a big contributor. And I will note, while it's not simulated
in this program, a lot of write-misses will result in a lot of direct writes to
memory, which will slow down a program in general.

\section{Next-line Prefetching}

This method seemed to be the best method we could get. It generally performed
better than the general Set-Associative cache and frequently beat the accurate
but inefficient Fully-Associative cache. The most optimal configuration of this
type was the 16-way version which consistently performed better most other
configurations, only being occasionally beaten out by the 16 KB direct cache
oddly enough.

\subsection{Prefetch on Miss}

Preftching only on a miss gave good results, generally better than the
Set-Associative cache, but like with the write-on-miss Set-Associative cache,
this version of a prefetching cache was still slightly less accurate.

\end{document}
